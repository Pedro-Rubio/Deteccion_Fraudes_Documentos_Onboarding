# üìÜ Plan T√©cnico de Proyecto ‚Äî Document Fraud Sentinel (Versi√≥n Medallion)

> **Coordinaci√≥n y Direcci√≥n T√©cnica:** Pedro Rubio  
> Proyecto integral de detecci√≥n de fraude documental en procesos de onboarding bancario digital.

---

## üéØ Prop√≥sito

Desarrollar un sistema completo de detecci√≥n de fraude en documentos de identidad (DNI y pasaportes), estructurado bajo un enfoque **Data Lakehouse con arquitectura Medallion (Bronze ‚Üí Silver ‚Üí Gold)**.  
El proyecto integra visi√≥n computacional, machine learning multimodal, y monitoreo operativo continuo.

Duraci√≥n estimada: **12 semanas**  
Equipo base: Data Engineering, Data Science, MLOps y Backend.

---

## üèóÔ∏è Estructura General del Proyecto

**Capas principales:**
- ü•â **Bronze:** ingesta cruda y almacenamiento original.
- ü•à **Silver:** datos curados, enriquecidos y con features forenses.
- ü•á **Gold:** dataset anal√≠tico y ML-ready.
- üß† **Feature Store:** vistas online/offline para scoring en tiempo real.

**Infraestructura base:**  
Google Colab (desarrollo exploratorio) + Airflow (orquestaci√≥n) + FastAPI (serving) + Prometheus/Grafana (monitoreo).

---

## üß± Fase 1 ‚Äî An√°lisis y Dise√±o (Semanas 1‚Äì2)

| Semana | Actividades principales | Entregables |
|--------|--------------------------|--------------|
| 1 | Definici√≥n de requerimientos t√©cnicos y de negocio. Dise√±o del flujo de onboarding y arquitectura Medallion. | Documento de dise√±o y diagrama de arquitectura. |
| 2 | Identificaci√≥n de fuentes de datos, definici√≥n de esquemas para Bronze y validaci√≥n de dataset sint√©tico. | Esquemas de tablas Bronze + dataset inicial (sint√©tico). |

üîπ **Resultado esperado:** arquitectura validada, estructura inicial del Lakehouse lista.

---

## ü•â Fase 2 ‚Äî Capa Bronze: Ingesta de Datos (Semanas 3‚Äì4)

| Semana | Actividades principales | Entregables |
|--------|--------------------------|--------------|
| 3 | Desarrollo de jobs de ingesta (JSON, im√°genes, OCR, metadatos). | Job Airflow `bronze_ingest.py` con persistencia en storage. |
| 3 | Configuraci√≥n de almacenamiento (ruta de im√°genes y logs). | Estructura `/data/bronze/` organizada. |
| 4 | Validaci√≥n y control de calidad inicial (schema + logs). | Data dictionary y scripts de validaci√≥n Great Expectations. |

üîπ **Resultado esperado:** capa Bronze funcional con hist√≥rico completo de eventos.

---

## ü•à Fase 3 ‚Äî Capa Silver: Curado y Enriquecimiento (Semanas 5‚Äì6)

| Semana | Actividades principales | Entregables |
|--------|--------------------------|--------------|
| 5 | Limpieza y normalizaci√≥n de campos. | Script `silver_enrich.py` (parseo JSON, normalizaci√≥n). |
| 5 | C√°lculo de features visuales (ELA, blur, pHash) y contextuales. | Job de extracci√≥n forense y contextual. |
| 6 | Integraci√≥n con OCR y MRZ, detecci√≥n de inconsistencias. | Tabla `doc_text_features_silver`. |
| 6 | Consolidaci√≥n de todas las fuentes en tablas Silver unificadas. | DataFrame unificado `doc_enriched_silver.parquet`. |

üîπ **Resultado esperado:** capa Silver estable y lista para consumo anal√≠tico y modelado.

---

## ü•á Fase 4 ‚Äî Capa Gold: Dataset Anal√≠tico y ML-Ready (Semanas 7‚Äì8)

| Semana | Actividades principales | Entregables |
|--------|--------------------------|--------------|
| 7 | Integraci√≥n de todas las tablas Silver + etiquetas. | Tabla `fraud_doc_onboarding_gold`. |
| 7 | Generaci√≥n de variables derivadas y feature importance inicial. | Dataset final curado (`features_merged.csv`). |
| 8 | Validaci√≥n de integridad (joins, nulls, duplicados). | Scripts Great Expectations. |
| 8 | Publicaci√≥n en Feature Store (Feast). | `fs_doc_features_v1`, `fs_user_risk_v1`, `fs_device_risk_v1`. |

üîπ **Resultado esperado:** dataset Gold completo y sincronizado con la Feature Store.

---

## üß† Fase 5 ‚Äî Modelado Multimodal (Semanas 9‚Äì10)

| Semana | Actividades principales | Entregables |
|--------|--------------------------|--------------|
| 9 | Entrenamiento de modelo CNN (im√°genes) y XGBoost (tabular). | Modelos `.onnx` y `.pkl` registrados en MLflow. |
| 9 | Implementaci√≥n de fusi√≥n tard√≠a (logistic regression calibrada). | Modelo final `fraud_fusion_v1`. |
| 10 | Evaluaci√≥n y explicabilidad (Grad-CAM + SHAP). | Reporte de interpretabilidad y m√©tricas. |
| 10 | Validaci√≥n del modelo en dataset Gold. | Recall > 85%, FPR < 5%. |

üîπ **Resultado esperado:** modelo final validado y registrado en MLflow.

---

## ‚öôÔ∏è Fase 6 ‚Äî Despliegue y API de Scoring (Semana 11)

| Semana | Actividades principales | Entregables |
|--------|--------------------------|--------------|
| 11 | Desarrollo de API FastAPI con endpoints `/score` y `/metrics`. | `app/main.py` operativo. |
| 11 | Integraci√≥n del modelo ONNX en inferencia. | Pipeline completo de scoring con Feature Store. |
| 11 | Despliegue local con Docker Compose. | Stack `FastAPI + Prometheus + Grafana`. |
| 11 | Pruebas unitarias e integraci√≥n (Pytest). | Tests funcionales aprobados. |

üîπ **Resultado esperado:** servicio en funcionamiento con m√©tricas expuestas.

---

## üìä Fase 7 ‚Äî Monitoreo, Drift y Observabilidad (Semana 12)

| Semana | Actividades principales | Entregables |
|--------|--------------------------|--------------|
| 12 | Configuraci√≥n de Prometheus y dashboards Grafana. | Paneles de latencia, drift y score. |
| 12 | Integraci√≥n de Evidently para monitoreo de drift y PSI. | Jobs `monitor_drift.py` conectados a Prometheus. |
| 12 | Configuraci√≥n de alertas autom√°ticas (Grafana/Slack). | Alertas ‚Äúlatencia > 2s‚Äù y ‚ÄúPSI > 0.2‚Äù. |

üîπ **Resultado esperado:** monitoreo continuo de modelo y datos en producci√≥n.

---

## üß© Fase 8 ‚Äî Streamlit y Validaci√≥n Operativa (Post 12 semanas)

| Semana | Actividades principales | Entregables |
|--------|--------------------------|--------------|
| 13 | Desarrollo de app Streamlit para revisi√≥n manual. | `app/streamlit_review.py`. |
| 13 | Integraci√≥n con endpoint `/score`. | Consola de analistas con Grad-CAM y SHAP visibles. |
| 14 | Pruebas con casos reales/sint√©ticos y feedback del equipo de fraude. | Informe de usabilidad y performance. |

üîπ **Resultado esperado:** interfaz operativa interna para revisi√≥n de casos sospechosos.

---

## üìà KPIs T√©cnicos y de Negocio

| Indicador | Meta | Descripci√≥n |
|------------|------|-------------|
| Recall (fraude) | > 85% | Detecci√≥n efectiva de fraude documental |
| FPR | < 5% | M√≠nimo rechazo a clientes leg√≠timos |
| Latencia (P95) | < 2s | Respuesta r√°pida para onboarding |
| PSI (drift) | < 0.2 | Estabilidad del modelo |
| % reducci√≥n revisiones manuales | -30% | Eficiencia operativa |
| Disponibilidad del servicio | 99.5% | Uptime del scoring API |

---

## üß≠ Gobernanza y Coordinaci√≥n

| Frecuencia | Reuni√≥n | Objetivo |
|-------------|----------|----------|
| Diario | Daily standup (10‚Äì15 min) | Seguimiento t√©cnico |
| Semanal | Sprint review | Validar avances e hitos |
| Quincenal | Retro + planificaci√≥n | Ajuste de backlog y prioridades |
| Mensual | Comit√© de riesgo | Evaluar m√©tricas del modelo |

---

## üßæ Comentario final

El proyecto combina **ingenier√≠a de datos, machine learning y monitoreo operativo** dentro de un mismo flujo controlado.  
El uso de la arquitectura **Medallion** permite mantener trazabilidad completa, facilitando auditor√≠as y retraining continuo sin perder consistencia.

---

**Pedro Rubio**  
_Data & ML Analyst ‚Äî Coordinador T√©cnico del Proyecto_  
üìß srdelosdatos@gmail.com ¬∑ üåê [github.com/srdelosdatos](https://github.com/srdelosdatos)
